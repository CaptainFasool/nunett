#!/bin/bash
#
## @file        nunet
## @authors     Dagim Sisay <dagim@nunet.io>, Avimanyu Bandyopadhyay <avimanyu.bandyopadhyay@nunet.io>
## @licence     AGPL

# NuNet CLI - Device Management Service

GOOD_C='\033[32m'   # GREEN
INFO_C='\033[33m' # YELLOW
BAD_C='\033[31m'    # RED
NORMAL_C='\033[0m'

SELF_NAME=$(basename $0)

DMS_HOST=localhost
DMS_PORT=9999

usage() {
    echo -e "Usage: $SELF_NAME [OPTIONS] COMMAND\n"
    echo -e "Command line interface for the NuNet Device Management Service.\n"
    echo "Options:"
    echo "    -v, --verbose    Verbose output"
    echo -e "    -p, --pretty     Prettified JSON output\n"
    echo "Commands:"
    echo "  capacity            Display capacity of device resources"
    echo "  wallet              Get Current Wallet Address"
    echo "  onboard             Onboard the device to NuNet"
    echo "  info                Get info about currently onboarded machine"
    echo "  onboard-gpu         Install NVIDIA/AMD GPU driver and Container Runtime"
    echo "  onboard-ml          Prepare the system for Machine Learning with GPU"
    echo "  resource-config     Change the configuration of onboarded device"
    echo "  shell               Send commands and receive answers to a vm instance via DMS"
    echo "  peer                Interact with currently visible peers"
    echo "  chat                Start,Join or List Chat Requests"
    echo "  log                 Returns the path of an archive containing all log files"
    echo -e "  version             Current DMS Version \n"
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

capacity_usage() {
    echo -e "Usage: $SELF_NAME capacity [OPTIONS]\n"
    echo -e "Command line interface for the NuNet Device Management Service.\n"
    echo "Options:"
    echo "    -v, --verbose           Verbose output"
    echo "    -f, --full              Display full capacity of machine"
    echo "    -o, --onboarded         Display onboarded/dedicated amount of resources to nunet"
    echo "    -a, --available         Display availale capacity of machine"
    echo "    -p, --pretty            Prettified JSON output"
    echo "    -gpu, --gpu-status      Check GPU Status in real time"
    echo "    -ct, --cuda-tensor      Check availability of CUDA and Tensor Cores"
    echo "    -rh, --rocm-hip         Check availability of ROCm and HIP"
    echo -e "    -h, --help              This Menu\n"
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

wallet_usage() {
    echo -e "Usage: $SELF_NAME wallet COMMAND \n"
    echo -e "Manage blockchain wallet.\n"
    echo "Commands:"
    echo -e "  new         Create a new wallet address. Returns public and private keys.\n"
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

wallet_new_usage() {
    echo -e "Usage: $SELF_NAME wallet new [OPTIONS] \n"
    echo -e "Create new blockchain wallet.\n"
    echo "Options:"
    echo "    -c, --cardano    Create a new Cardano wallet address."
    echo "    -e, --ethereum   Create a new Ethereum wallet address."
    echo "    -p, --pretty     Pretty Print Output"
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

onboard_usage() {
    echo -e "Usage: $SELF_NAME {-mcna} [-Cvp]\n"
    echo -e "Onboard the current machine to the NuNet platform.\n"
    echo "Options:"
    echo "    -m, --memory           Amount of memory in Megabytes"
    echo "    -c, --cpu              Amount of CPU in Megahertz"
    echo "    -n, --nunet-channel    NuNet channel to onboard the machine to:"
    echo "                             OPTIONS"
    echo "                               'nunet-test' - Development branch for Community Testers"
    echo "                               'nunet-staging' - Staging branch for Community Testers"
    echo "    -a, --address          Wallet Address (Public Key)"
    echo "    -C, --cardano          Allow deployment of a Cardano Node"
    echo "    -l, --local-enable     Enable Using Private Addresses. By default, server mode is enabled"
    echo "                           which prevents the DMS from scanning local networkk. It's recommended"
    echo "                           that users don't enable local addresses when running in datacenters."
    echo "    -v, --verbose          Verbose output"
    echo -e "    -p, --pretty           Prettified JSON output\n"
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

peer_usage() {
    echo -e "Usage: $SELF_NAME peer COMMAND [OPTIONS] \n"
    echo -e "Interact with connected peers.\n"
    echo "Commands:"
    echo "  list         List visible peers."
    echo -e "  self         Show self peer info.\n"
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

chat_usage() {
    echo -e "Usage: $SELF_NAME chat COMMAND \n"
    echo -e "Chat With Peers.\n"
    echo "Commands:"
    echo "  start        Start Chat With Peer."
    echo "  list         List Open Chat Requests."
    echo "  clear        Clear Open Chat Requests."
    echo -e "  join         Join a Chat Stream Using Request ID."
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

chat_start_usage() {
    echo -e "Usage: $SELF_NAME chat start <PEER_ID> \n"
    echo -e "Start a chat request to PEER_ID.\n"
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

chat_join_usage() {
    echo -e "Usage: $SELF_NAME chat join <REQUEST_ID> \n"
    echo -e "Join a chat request by another peer.\n"
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

resource_config_usage() {
    echo -e "Usage: $SELF_NAME config [-mcvp] \n"
    echo -e "Change the configuration of onboarded device for make available on nunet.\n"
    echo "Options:"
    echo "    -m, --memory           Amount of memory in Megabytes"
    echo "    -c, --cpu              Amount of CPU in Megahertz"
    echo "    -v, --verbose          Verbose output"
    echo -e "    -p, --pretty           Prettified JSON output\n"
    echo "For more information, visit https://gitlab.com/nunet/device-management-service/-/wikis/home"
    exit
}

gpu_status() {
    if ! command -v nvidia-smi > /dev/null && ! command -v rocm-smi > /dev/null; then
        printf "${BAD_C}Unable to find 'nvidia-smi' or 'rocm-smi'.\nNeither NVIDIA nor AMD GPU driver is installed.${NORMAL_C}\n"
        exit
    fi

    while :
    do
        clear
        printf "${INFO_C}========== NuNet GPU Status ==========\n\n${NORMAL_C}"

        printf "${GOOD_C}GPU Utilization:${INFO_C}\n"

        if command -v nvidia-smi > /dev/null; then
            nvidia-smi --query-gpu=index,name,utilization.gpu --format=csv,noheader
        fi

        if command -v rocm-smi > /dev/null; then
            rocm-smi --showid --showproductname | grep "GPU ID" | awk -F'[][]' '{printf $2 ", "}'
            rocm-smi --showid --showproductname | grep 'Card series' | awk -F'[][]' '{printf "AMD " $4 ", "}'
            rocm-smi --showuse | awk -F': ' '/GPU use/{print $3 " %"}'
        fi

        printf "${GOOD_C}\nMemory Utilization:${INFO_C}\n"

        if command -v nvidia-smi > /dev/null; then
            nvidia-smi --query-gpu=index,name,memory.used --format=csv,noheader
        fi

        if command -v rocm-smi > /dev/null; then
            rocm-smi --showid --showproductname | grep "GPU ID" | awk -F'[][]' '{printf $2 ", "}'
            rocm-smi --showid --showproductname | grep 'Card series' | awk -F'[][]' '{printf "AMD " $4 ", "}'
            rocm-smi --showmeminfo vis_vram | grep 'Total Used Memory' | awk -F': ' '{printf "%.2d MiB\n", $3/1048576}'
        fi

        printf "${GOOD_C}\nMemory Free:${INFO_C}\n"

        if command -v nvidia-smi > /dev/null; then
            nvidia-smi --query-gpu=index,name,memory.free --format=csv,noheader
        fi

        if command -v rocm-smi > /dev/null; then
            rocm-smi --showid --showproductname | grep "GPU ID" | awk -F'[][]' '{printf $2 ", "}'
            rocm-smi --showid --showproductname | grep 'Card series' | awk -F'[][]' '{printf "AMD " $4 ", "}'
            rocm-smi --showmeminfo vis_vram | awk -F': ' '/Total Memory \(B\)/{total=$3} /Total Used Memory \(B\)/{used=$3} END{printf "%d MiB\n", (total-used)/1048576}'
        fi

        printf "${GOOD_C}\nMemory Capacity:${INFO_C}\n"

        if command -v nvidia-smi > /dev/null; then
            nvidia-smi --query-gpu=index,name,memory.total --format=csv,noheader
        fi
 
        if command -v rocm-smi > /dev/null; then
            rocm-smi --showid --showproductname | grep "GPU ID" | awk -F'[][]' '{printf $2 ", "}'
            rocm-smi --showid --showproductname | grep 'Card series' | awk -F'[][]' '{printf "AMD " $4 ", "}'
            rocm-smi --showmeminfo vis_vram | grep 'Total Memory' | awk -F': ' '{printf "%.2d MiB\n", $3/1048576}'
        fi

        printf "${GOOD_C}\nTemperature:${INFO_C}\n"

        if command -v nvidia-smi > /dev/null; then
            nvidia-smi --query-gpu=index,temperature.gpu --format=csv,noheader | awk '{printf "GPU %d: %d°C\n", $1, $2}'
        fi

        if command -v rocm-smi > /dev/null; then
            rocm-smi --showid --showproductname | grep "GPU ID" | awk -F'[][]' '{printf "GPU " $2 ": "}'
            rocm-smi --showtemp | awk -F': ' '/Sensor junction/{printf "%.2d°C\n", $3}'
        fi

        printf "${GOOD_C}\nPower Draw:${INFO_C}\n"

        if command -v nvidia-smi > /dev/null; then
            nvidia-smi --query-gpu=index,name,power.draw --format=csv,noheader
        fi

        if command -v rocm-smi > /dev/null; then
            rocm-smi --showid --showproductname | grep "GPU ID" | awk -F'[][]' '{printf $2 ", "}'
            rocm-smi --showid --showproductname | grep 'Card series' | awk -F'[][]' '{printf "AMD " $4 ", "}'
            rocm-smi --showpower | awk -F': ' '/Average Graphics Package Power/{printf "%.2f W\n", $3}'
        fi

        printf "${NORMAL_C}\nPress [CTRL+C] to exit..\n"
        printf "Refreshing status in a few seconds..."
        sleep 10
    done
}

check_cuda_tensor() {
    image_exist=$(docker images | grep "registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch")
    if [ ! -n "$image_exist" ] ; then
        while true; do
            read -p "This command is meant only for supported NVIDIA GPUs. Are you sure you want to proceed?? (yes/no) " check_cuda_resp
            case $check_cuda_resp in
                yes )  printf "${INFO_C}Proceeding...\n${NORMAL_C}";
                    # XXX: it's better we implement this through the DMS in future;;
                    docker run -ti --rm --entrypoint "" --gpus all registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch python check-cuda-and-tensor-cores-availability.py
                    exit
                    ;;
                no) echo "Exiting...";
                    exit;;
                *) echo "Only 'yes' or 'no' please";;
            esac
        done
    fi
    docker run -ti --rm --entrypoint "" --gpus all registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch python check-cuda-and-tensor-cores-availability.py
}

check_rocm_hip() {
    image_exist=$(docker images | grep "registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch-amd")
    if [ ! -n "$image_exist" ] ; then
        while true; do
            read -p "This command is meant only for supported AMD GPUs. Are you sure you want to proceed?? (yes/no) " check_rocm_resp
            case $check_rocm_resp in
                yes )  printf "${INFO_C}Proceeding...\n${NORMAL_C}";
                    # XXX: it's better we implement this through the DMS in future;;
                    docker run -ti --rm --entrypoint "" --device=/dev/kfd --device=/dev/dri --group-add video --group-add render registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch-amd python check-rocm-and-hip-availability.py
                    exit
                    ;;
                no) echo "Exiting...";
                    exit;;
                *) echo "Only 'yes' or 'no' please";;
            esac
        done
    fi
    docker run -ti --rm --entrypoint "" --device=/dev/kfd --device=/dev/dri --group-add video --group-add render registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch-amd python check-rocm-and-hip-availability.py
}

capacity() {
    if [[ ${#@} -lt 1 ]] ; then
        capacity_usage
        exit
    else
        avargs=($@)
        for avarg in "${avargs[@]}"; do
            case $avarg in
                "-h" | "--help")
                    capacity_usage
                    ;;
                "-p" | "--pretty")
                    NPRETTY_OUT=1
                    ;;
                "-v" | "--verbose")
                    NVERBOSE_OUT=1
                    ;;
                "-f" | "--full")
                    NFULL_OUT=1
                    ;;
                "-o" | "--onboarded")
                    NONBOARD_OUT=1
                    ;;
                "-a" | "--available")
                    NAVAILABLE_OUT=1
                    ;;
                "-gpu" | "--gpu-status")
                    gpu_status
                    printf "${NORMAL_C}"
                    ;;                    
                "-ct" | "--cuda-tensor")
                    check_cuda_tensor
                    printf "${NORMAL_C}"
                    exit
                    ;;
                "-rh" | "--rocm-hip")
                    check_rocm_hip
                    printf "${NORMAL_C}"
                    exit
                    ;;                    
                *)
                    printf "${BAD_C}Bad argument \"$avarg\" for 'capacity' Command. ${NORMAL_C}\n"
                    exit
                    ;;
            esac
        done
    fi
    
    if [[ $NVERBOSE_OUT -eq 1 ]]; then
        NFULL_OUT=1
        NONBOARD_OUT=1
        NAVAILABLE_OUT=1
    fi
    N_INFO=$(info)
    N_C_OUT=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/onboarding/provisioned)
    if [[ $N_INFO == *"Error:"* ]] ; then
        if [[ $NPRETTY_OUT -eq 1 ]] ; then
            if [[ $NFULL_OUT -eq 1 ]]; then
                echo "Total Machine Capacity"
                echo $N_C_OUT | jq 
                echo
            fi
            if [[ $NONBOARD_OUT -eq 1 ]]; then
                echo "Reserved for Nunet"
                echo '{ "cpu": 0, "memory": 0 }' | jq 
                echo
            fi
            if [[ $NAVAILABLE_OUT -eq 1 ]]; then
                echo "Available Machine Capacity"
                echo $N_C_OUT | jq
                echo
            fi
        else
            if [[ $NFULL_OUT -eq 1 ]]; then
                echo "Total Machine Capacity"
                echo $N_C_OUT
                echo
            fi
            if [[ $NONBOARD_OUT -eq 1 ]]; then
                echo "Reserved for Nunet"
                echo '{"cpu": 0, "memory": 0}'
                echo
            fi
            if [[ $NAVAILABLE_OUT -eq 1 ]]; then
                echo "Available Machine Capacity"
                echo $N_C_OUT
                echo
            fi
        fi
    else
        if [[ $NPRETTY_OUT -eq 1 ]] ; then
            if [[ $NFULL_OUT -eq 1 ]]; then
                echo "Total Machine Capacity"
                echo $N_C_OUT | jq
                echo
            fi
            if [[ $NONBOARD_OUT -eq 1 ]]; then
                echo "Reserved for Nunet"
                N_ONBOARD=$(echo $N_INFO | jq '.reserved')
                echo $N_ONBOARD | jq
                echo
            fi
            if [[ $NAVAILABLE_OUT -eq 1 ]]; then
                echo "Available Machine Capacity"
                N_AVAILABLE=$(echo $N_INFO | jq '.available')
                echo $N_AVAILABLE | jq
                echo
            fi
        else
            if [[ $NFULL_OUT -eq 1 ]]; then
                echo "Total Machine Capacity"
                echo $N_C_OUT
                echo
            fi
            if [[ $NONBOARD_OUT -eq 1 ]]; then
                echo "Reserved for Nunet"
                N_ONBOARD=$(echo $N_INFO | jq '.reserved')
                echo $N_ONBOARD
                echo
            fi
            if [[ $NAVAILABLE_OUT -eq 1 ]]; then
                echo "Available Machine Capacity"
                N_AVAILABLE=$(echo $N_INFO | jq '.available')
                echo $N_AVAILABLE
                echo
            fi
        fi
    fi
}

wallet_new() {
    if [[ ${#@} -lt 1 ]] ; then
        wallet_new_usage
    fi

    N_WALLET_NEW_OPTS=$(getopt -a -n nunet-wallet-new -o ecp --long ethereum,cardano,pretty -- "$@")
    eval set -- "$N_WALLET_NEW_OPTS"

    while :
        do
            case "$1" in
                -c | --cardano)       N_CREATE_WALLET_CARDANO=1  ; shift ;;
                -e | --ethereum)      N_CREATE_WALLET_ETHEREUM=1   ; shift ;;
                -p | --pretty)        N_CREATE_WALLET_PRETTY=1    ; shift ;;
                --) shift; break ;;
                *) echo "Unexpected option: $1."
                    wallet_new_usage ;;
            esac
    done

    if [[ $N_CREATE_WALLET_ETHEREUM -eq 1 && $N_CREATE_WALLET_CARDANO -eq 1 ]] ; then
        printf "${BAD_C}Error! Can not create both Ethereum and Cardano Wallets.${NORMAL_C}\n"
        wallet_new_usage
        exit
    fi

    if [[ $N_CREATE_WALLET_ETHEREUM -eq 1 ]] ; then
        N_CREATE_WALLET=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/onboarding/address/new?blockchain=ethereum)
    elif [[ $N_CREATE_WALLET_CARDANO -eq 1 ]] ; then
        N_CREATE_WALLET=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/onboarding/address/new?blockchain=cardano)
    fi

    if [[ $N_CREATE_WALLET_PRETTY -eq 1 ]] ; then
        echo $N_CREATE_WALLET | jq
    else
        echo $N_CREATE_WALLET
    fi

}

wallet() {
    if [[ ${#@} -lt 1 ]] ; then
        wallet_usage
    fi

    args=($@)
    subcmd=$1

    walletsubcmds=("new") # list of sub-sub-commands for wallet sub-command

    if [[ " ${walletsubcmds[*]} " =~ " ${subcmd} " ]] ; then
       wallet_$subcmd ${args[@]:1}
    else
        printf "${BAD_C}Not yet implemented. Only 'wallet new' at this time.${NORMAL_C}\n"
        wallet_usage
    fi
}

onboard() {
    N_ONBOARD_OPTS=$(getopt -a -n nunet-onboard -o m:c:n:a:Clvp: --long memory:,cpu:,nunet-channel:,address:,cardano,local-enable,verbose,pretty -- "$@")
    eval set -- "$N_ONBOARD_OPTS"

    N_ONBOARD_CARDANO=false
    N_ONBOARD_SERVER_MODE=true

    if [[ ${#@} -le 1 ]] ; then
        onboard_usage
    fi

    while :
        do
            case "$1" in
                -m | --memory)        N_ONBOARD_MEM="$2"         ; shift 2 ;;
                -c | --cpu)           N_ONBOARD_CPU="$2"         ; shift 2 ;;
                -n | --nunet-channel) N_ONBOARD_CHAN="$2"        ; shift 2 ;;
                -a | --address)       N_ONBOARD_ADD="$2"         ; shift 2 ;;
                -C | --cardano)       N_ONBOARD_CARDANO=true     ; shift ;;
                -l | --local-enable)        N_ONBOARD_SERVER_MODE=false ; shift ;;
                -v | --verbose)       N_ONBOARD_VERBOSE=1        ; shift ;;
                -p | --pretty)        N_ONBOARD_PRETTY=1         ; shift ;;
                --) shift; break ;;
                *) echo "Unexpected option: $1."
                    onboard_usage ;;
            esac
    done


    # validation
    [[ -z $N_ONBOARD_CPU ]] && printf "${BAD_C}Error: -c | --cpu must be specified.${NORMAL_C}\n" && onboard_usage
    [[ -z $N_ONBOARD_MEM ]] && printf "${BAD_C}Error: -m | --memory must be specified.${NORMAL_C}\n" && onboard_usage
    [[ -z $N_ONBOARD_CHAN ]] && printf "${BAD_C}Error: -n | --nunet-channel must be specified.${NORMAL_C}\n" && onboard_usage
    [[ -z $N_ONBOARD_ADD ]] && printf "${BAD_C}Error: -a | --address must be specified.${NORMAL_C}\n" && onboard_usage

    N_AVAILABLE_RES=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/onboarding/provisioned)
    N_AVAILABLE_MEM=$(echo $N_AVAILABLE_RES | jq ".memory")
    N_AVAILABLE_CPU=$(echo $N_AVAILABLE_RES | jq ".cpu")
    N_AVAILABLE_CPU=$(printf "%.0f" $(echo $N_AVAILABLE_CPU | bc)) # rounding in case of decimal values cpu freq such as cloud
    if [[ $N_ONBOARD_MEM -gt $((N_AVAILABLE_MEM*9/10)) || $N_ONBOARD_MEM -lt $((N_AVAILABLE_MEM/10)) ]] ; then
        printf "${BAD_C}Memory should be between 10%% and 90%% of the available memory ($((N_AVAILABLE_MEM/10)) and $((N_AVAILABLE_MEM*9/10))) ${NORMAL_C}\n"
        printf "${INFO_C}Check available resource with 'nunet capacity --available --pretty'${NORMAL_C}\n"
        exit
    elif [[ $N_ONBOARD_CPU -gt $((N_AVAILABLE_CPU*9/10)) || $N_ONBOARD_CPU -lt $((N_AVAILABLE_CPU/10)) ]] ; then
        printf "${BAD_C}CPU should be between 10%% and 90%% of the available CPU ($((N_AVAILABLE_CPU/10)) and $((N_AVAILABLE_CPU*9/10))) ${NORMAL_C}\n"
        printf "${INFO_C}Check available resource with 'nunet capacity --available --pretty'${NORMAL_C}\n"
        exit
    elif [[ "$N_ONBOARD_CHAN" != "nunet-test" && "$N_ONBOARD_CHAN" != "nunet-staging" && "$N_ONBOARD_CHAN" != "nunet-team" && "$N_ONBOARD_CHAN" != "nunet-edge" ]] ; then
        printf "${BAD_C}NuNet Channel should be 'nunet-test' or 'nunet-staging' not $N_ONBOARD_CHAN ${NORMAL_C}\n"
        exit
    else
        if [[ "$N_ONBOARD_CHAN" == "nunet-team" || "$N_ONBOARD_CHAN" == "nunet-edge" ]] ; then
            while true; do
                read -p "Are you sure you want to join $N_ONBOARD_CHAN?? (yes/no) " chan_resp
                case $chan_resp in
                    yes ) echo "Proceeding with onboarding to $N_ONBOARD_CHAN channel";
                        break;;
                    no) echo "Exiting...";
                        exit;;
                    *) echo "Only 'yes' or 'no' please";;
                esac
            done
        fi
        N_ONBOARD_RESPONSE=$(curl -s -X POST -H "Content-Type: application/json" \
            -d "{\"memory\": $N_ONBOARD_MEM, \"cpu\": $N_ONBOARD_CPU, \
            \"channel\":\"$N_ONBOARD_CHAN\", \"payment_addr\": \"$N_ONBOARD_ADD\", \
            \"cardano\": $N_ONBOARD_CARDANO, \"server_mode\": $N_ONBOARD_SERVER_MODE}" \
            $DMS_HOST:$DMS_PORT/api/v1/onboarding/onboard)
        # check if error
        N_ONBOARD_ERR_MSG=$(echo $N_ONBOARD_RESPONSE | jq '. | select(.error != null) | .error')
        if [[ ! -z $N_ONBOARD_ERR_MSG ]] ; then
            printf "${BAD_C}Error: $N_ONBOARD_ERR_MSG ${NORMAL_C}\n"
        else
            printf "${GOOD_C}Successfully Onboarded.${NORMAL_C}\n"
            [[ -z $N_ONBOARD_PRETTY ]] && echo $N_ONBOARD_RESPONSE || echo $N_ONBOARD_RESPONSE | jq
        fi
    fi

}

gpu_info() {

    # Use the uname command with the -a option to get system information
    system_info=$(uname -a)

    # Use grep to search for the string "microsoft" in the system information
    if echo "$system_info" | grep -qi "microsoft"; then
        # The string "microsoft" was found, so this is a WSL console
        printf "${INFO_C}You are using Windows Subsystem for Linux. Make sure you have an NVIDIA GPU and have installed the latest Windows Driver for your NVIDIA GPU before proceeding. AMD GPUs on WSL is not supported.${NORMAL_C}\n"
        sleep 5 # adding some time to read the message
    else
        # Check if nvidia-smi is installed
        if ! command -v nvidia-smi > /dev/null; then
          exit
        fi

        # Run nvidia-smi -L and save all NVIDIA GPU names on the machine
        nvidia_gpu_names=$(nvidia-smi -L)
        if [[ $nvidia_smi_output =~ "No devices were found" ]]; then
           printf "${BAD_C}Error: No NVIDIA GPUs were detected.${NORMAL_C}"
           exit
        else
           printf "${GOOD_C}\nNVIDIA GPU(s) detected.${NORMAL_C}\n"
           # Print the GPU names
           printf "${INFO_C}Available GPU(s):\n$nvidia_gpu_names${NORMAL_C}\n"
        fi
        
        # Check if rocm-smi is installed
        if ! command -v rocm-smi > /dev/null; then
          exit
        fi

        # Use rocm-smi and save all AMD GPU names on the machine
        amd_gpu_names=$(rocm-smi --showid --showproductname 2>/dev/null | grep 'Card series' | awk -F'[][]' '{printf "AMD " $4 "\n"}')
        if [[ $amd_smi_output =~ "No devices were found" ]]; then
           printf "${BAD_C}Error: No AMD GPUs were detected.${NORMAL_C}"
           exit
        else
           printf "${GOOD_C}\nAMD GPU(s) detected.${NORMAL_C}\n"
           # Print the GPU names
           printf "${INFO_C}Available GPU(s):\n$amd_gpu_names${NORMAL_C}\n"
        fi
        ml_info
    fi

}

ml_info() {
    nvidia_tensorflow_image="registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/tensorflow"
    amd_tensorflow_image="registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/tensorflow-amd"
    nvidia_pytorch_image="registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch"
    amd_pytorch_image="registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch-amd"

    nvidia_detected=0
    amd_detected=0

    if docker images | grep -q "$nvidia_tensorflow_image"; then
        printf "${GOOD_C}This machine is prepared to run NVIDIA TensorFlow ML jobs on NuNet.${NORMAL_C}\n"
        nvidia_detected=1
    fi

    if docker images | grep -q "$amd_tensorflow_image"; then
        printf "${GOOD_C}This machine is prepared to run AMD ROCm TensorFlow ML jobs on NuNet.${NORMAL_C}\n"
        amd_detected=1
    fi

    if docker images | grep -q "$nvidia_pytorch_image"; then
        printf "${GOOD_C}This machine is prepared to run NVIDIA PyTorch ML jobs on NuNet.${NORMAL_C}\n"
        nvidia_detected=1
    fi

    if docker images | grep -q "$amd_pytorch_image"; then
        printf "${GOOD_C}This machine is prepared to run AMD ROCm PyTorch ML jobs on NuNet.${NORMAL_C}\n"
        amd_detected=1
    fi

    if [[ $nvidia_detected -eq 0 && $amd_detected -eq 0 ]]; then
        printf "${BAD_C}NuNet ML images not detected. Please run 'nunet onboard-ml' command to prepare the machine for ML jobs.${NORMAL_C}\n"
    elif [[ $nvidia_detected -eq 1 && $amd_detected -eq 0 ]]; then
        printf "${INFO_C}Please note that only NVIDIA GPU ML jobs can be executed on this machine.${NORMAL_C}\n"
    elif [[ $nvidia_detected -eq 0 && $amd_detected -eq 1 ]]; then
        printf "${INFO_C}Please note that only AMD GPU ML jobs can be executed on this machine.${NORMAL_C}\n"
    else
        printf "${INFO_C}Both NVIDIA and AMD GPU ML jobs can be executed on this machine.${NORMAL_C}\n"
    fi
}

info() {
    N_INFO=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/onboarding/metadata)
    N_INFO_ERR_MSG=$(echo $N_INFO | jq '. | select(.error != null) | .error')
    if [[ ! -z $N_INFO_ERR_MSG ]] ; then
        printf "${BAD_C}Error: $N_INFO_ERR_MSG ${NORMAL_C}\n"
    else
        echo $N_INFO | jq
    fi
    gpu_info
}

peer() {
    if [[ ${#@} -ge 2 || ${#@} -lt 1 ]] ; then
        peer_usage
    else
        avargs=($@)
        for avarg in "${avargs[@]}"; do
            case $avarg in
                "list")
                    N_LIST_PEERS=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/peers)
                    N_LIST_PEERS_DHT=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/peers/dht)
                    ;;
                "self")
                    N_SELF_PEER=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/peers/self)
                    ;;
                *)
                    printf "${BAD_C}Bad argument \"$avarg\" for 'peer' Command. ${NORMAL_C}\n\n"
                    peer_usage
                    exit
                    ;;
            esac
        done
    fi

    if [[ -v N_LIST_PEERS ]] ; then
        N_LIST_PEERS_ERR_MSG=$(echo $N_LIST_PEERS | jq '. | select(.error != null) | .error' 2>/dev/null)
        if [[ ! -z "$N_LIST_PEERS_ERR_MSG" ]] ; then
            printf "${BAD_C}Error: $N_LIST_PEERS_ERR_MSG ${NORMAL_C}\n"
        elif [[ N_LIST_PEERS == "" ]] ; then
            printf "${BAD_C}No peers available. Please try again in a few minutes.${NORMAL_C}\n"
        else
            # echo $N_LIST_PEERS | jq --raw-output '(.[] | [.ID, ([.Addrs[]] | select(length > 0) | join(" , "))]) | map( gsub("\t";"\t") ) | join("|")' | column -t -N "ID,Listening Addresses" -c 150 -W2 --separator "|"
            printf "${UNDERLINE}Bootstrap peers${NORMAL}\n"
            echo $N_LIST_PEERS | jq --raw-output '(.[] | .ID)'
        fi
    elif [[ -v N_SELF_PEER ]] ; then
        N_SELF_PEER_ERR_MSG=$(echo $N_SELF_PEER | jq '. | select(.error != null) | .error')
        if [[ -z "$N_SELF_PEER_ERR_MSG" ]] ; then
            # echo $N_SELF_PEER | jq --raw-output '(. | [.ID, ([.Addrs[]] | select(length > 0) | join(" , "))]) | map( gsub("\t";"\t") ) | join("|")' | column -t -N "ID,Listening Addresses" -c 150 -W2 --separator "|"
            echo $N_SELF_PEER | jq --raw-output '(. | [.ID, ([.Addrs[]] | select(length > 0) | join(" , "))]) | map( gsub("\t";"\t") ) | join("   ")'
        else
            printf "${BAD_C}Error: $N_SELF_PEER_ERR_MSG ${NORMAL_C}\n"
        fi
    fi
    if [[ -v N_LIST_PEERS_DHT ]] ; then
        N_LIST_PEERS_DHT_ERR_MSG=$(echo $N_LIST_PEERS_DHT | jq '. | select(.error != null) | .error' 2>/dev/null)
        if [[ ! -z "$N_LIST_PEERS_DHT_ERR_MSG" ]] ; then
            printf "${BAD_C}Error: $N_LIST_PEERS_DHT_ERR_MSG ${NORMAL_C}\n"
        elif [[ N_LIST_PEERS_DHT == "" ]] ; then
            printf "${BAD_C}No peers available in DHT. Please try again in a few minutes.${NORMAL_C}\n"
        else
            printf "\n${UNDERLINE}DHT peers${NORMAL}\n"
            echo "$N_LIST_PEERS_DHT" | jq --raw-output '(.[])'
        fi
    fi    
}

default-depreq-peer() {
    if [[ -z $1 ]] ; then
        # echo "Usage: $SELF_NAME default-depreq-peer"
        N_DEFAULT_DEPREQ_PEER_RESP=$(curl -s "http://$DMS_HOST:$DMS_PORT/api/v1/peers/depreq")
    else
        # echo "Usage: $SELF_NAME default-depreq-peer [PEER_ID]"
        N_DEFAULT_DEPREQ_PEER_RESP=$(curl -s "http://$DMS_HOST:$DMS_PORT/api/v1/peers/depreq?peerID=$1")
    fi
    N_DEFAULT_DEPREQ_PEER_RESP_ERR_MSG=$(echo $N_DEFAULT_DEPREQ_PEER_RESP | jq '. | select(.error != null) | .error')
    if [[ -z "$N_DEFAULT_DEPREQ_PEER_RESP_ERR_MSG" ]] ; then
        # echo $N_SELF_PEER | jq --raw-output '(. | [.ID, ([.Addrs[]] | select(length > 0) | join(" , "))]) | map( gsub("\t";"\t") ) | join("|")' | column -t -N "ID,Listening Addresses" -c 150 -W2 --separator "|"
        echo $N_DEFAULT_DEPREQ_PEER_RESP | jq --raw-output .message
    else
        printf "${BAD_C}Error: $N_DEFAULT_DEPREQ_PEER_RESP_ERR_MSG ${NORMAL_C}\n"
    fi
}



resource-config() {
    N_CONFIG_OPTS=$(getopt -a -n nunet-onboard-config -o m:c:vp: --long memory:,cpu:,verbose,pretty -- "$@")
    eval set -- "$N_CONFIG_OPTS"
    if [[ ${#@} -le 1 ]] ; then
        resource_config_usage
    fi

    while :
        do
            case "$1" in
                -m | --memory)        N_CONFIG_MEM="$2"         ; shift 2 ;;
                -c | --cpu)           N_CONFIG_CPU="$2"         ; shift 2 ;;
                -v | --verbose)       N_CONFIG_VERBOSE=1        ; shift ;;
                -p | --pretty)        N_CONFIG_PRETTY=1         ; shift ;;
                --) shift; break ;;
                *) echo "Unexpected option: $1."
                    config_usage ;;
            esac
    done

    [[ -z $N_CONFIG_CPU ]] && printf "${BAD_C}Error: -c | --cpu must be specified.${NORMAL_C}\n" && config_usage
    [[ -z $N_CONFIG_MEM ]] && printf "${BAD_C}Error: -m | --memory must be specified.${NORMAL_C}\n" && config_usage

    N_AVAILABLE_RES=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/onboarding/provisioned)
    N_AVAILABLE_MEM=$(echo $N_AVAILABLE_RES | jq ".memory")
    N_AVAILABLE_CPU=$(echo $N_AVAILABLE_RES | jq ".cpu")
    N_AVAILABLE_CPU=$(printf "%.0f" $(echo $N_AVAILABLE_CPU | bc)) # rounding in case of decimal values cpu freq such as cloud

    if [[ $N_CONFIG_MEM -gt $((N_AVAILABLE_MEM*9/10)) || $N_CONFIG_MEM -lt $((N_AVAILABLE_MEM/10)) ]] ; then
        printf "${BAD_C}Memory should be between 10%% and 90%% of the available memory ($((N_AVAILABLE_MEM/10)) and $((N_AVAILABLE_MEM*9/10))) ${NORMAL_C}\n"
        printf "${INFO_C}Check capacity of resources with 'nunet capacity --pretty'${NORMAL_C}\n"
        exit
    elif [[ $N_CONFIG_CPU -gt $((N_AVAILABLE_CPU*9/10)) || $N_CONFIG_CPU -lt $((N_AVAILABLE_CPU/10)) ]] ; then
        printf "${BAD_C}CPU should be between 10%% and 90%% of the available CPU ($((N_AVAILABLE_CPU/10)) and $((N_AVAILABLE_CPU*9/10))) ${NORMAL_C}\n"
        printf "${INFO_C}Check capacity of resources with 'nunet capacity --pretty'${NORMAL_C}\n"
        exit
    else
        N_CONFIG_RESPONSE=$(curl -s -X POST -H "Content-Type: application/json" \
            -d "{\"memory\": $N_CONFIG_MEM, \"cpu\": $N_CONFIG_CPU}" \
            $DMS_HOST:$DMS_PORT/api/v1/onboarding/resource-config)
        # check if error
        N_CONFIG_ERR_MSG=$(echo $N_CONFIG_RESPONSE | jq '. | select(.error != null) | .error')
        if [[ ! -z $N_CONFIG_ERR_MSG ]] ; then
            printf "${BAD_C}Error: $N_CONFIG_ERR_MSG ${NORMAL_C}\n"
        else
            printf "${GOOD_C}Resources Changed Successfully.${NORMAL_C}\n"
            [[ -z $N_CONFIG_PRETTY ]] && echo $N_CONFIG_RESPONSE || echo $N_CONFIG_RESPONSE | jq
        fi
    fi
}


chat_start() {
    if [[ ${#@} -eq 1 ]] ; then
        websocat -Et "ws://$DMS_HOST:$DMS_PORT/api/v1/peers/chat/start?peerID=$1"
    else
        chat_start_usage
    fi
}


chat_list() {
    N_CHAT_LIST=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/peers/chat)
    N_CHAT_LIST_ERR_MSG=$(echo $N_CHAT_LIST | jq '. | select(.error != null) | .error' 2>/dev/null)
    if [[ -z "$N_CHAT_LIST_ERR_MSG" ]] ; then
        echo $N_CHAT_LIST | jq --raw-output '["ID", "Time-Opened"],(.[] | [.ID , .TimeOpened]) | @tsv'
    else
        printf "${BAD_C}Error: $N_CHAT_LIST_ERR_MSG ${NORMAL_C}\n"
    fi
}

chat_clear() {
    N_CHAT_CLEAR=$(curl -s $DMS_HOST:$DMS_PORT/api/v1/peers/chat/clear)
    N_CHAT_CLEAR_ERR_MSG=$(echo $N_CHAT_CLEAR | jq '. | select(.error != null) | .error' 2>/dev/null)
    if [[ -z "$N_CHAT_CLEAR_ERR_MSG" ]] ; then
        echo $N_CHAT_CLEAR | jq '. | select(.message != null) | .message' 2>/dev/null
    else
        printf "${BAD_C}Error: $N_CHAT_CLEAR_ERR_MSG ${NORMAL_C}\n"
    fi
}

chat_join() {
    if [[ ${#@} -eq 1 ]] ; then
        websocat -Et "ws://$DMS_HOST:$DMS_PORT/api/v1/peers/chat/join?streamID=$1"
    else
        chat_join_usage
    fi
}


chat() {
    if [[ ${#@} -lt 1 ]] ; then
        chat_usage
    fi

    args=($@)
    subcmd=$1

    chatsubcmds=("start" "list" "join" "clear") # list of sub-sub-commands for chat sub-command

    if [[ " ${chatsubcmds[*]} " =~ " ${subcmd} " ]] ; then
       chat_$subcmd ${args[@]:1}
    else
        printf "${BAD_C}Uknown Argument.${NORMAL_C}\n"
        chat_usage
    fi
}


secure_boot_check() {
    #Check for Secure Boot before proceeding with GPU driver installation, alert user with necessary information if yes.
    sudo apt install -y mokutil
    secure_boot_check="$(mokutil --sb-state | grep enabled)"
    secure_boot="enabled"
    if grep -q "$secure_boot" <<<"$secure_boot_check"; then
        printf "${INFO_C}************Important Note!!!************\n"
        printf "Your system has UEFI Secure Boot enabled.\n"
        printf "*****************************************\n"
        printf "a. NVIDIA GPU Driver installation will require you to enroll a password(confirmed twice) as a machine owner key(MOK).\n"
        printf "b. Reboot your system after finishing the onboarding procedure.\n"
        printf "c. Make sure you select “Enroll MOK” before Linux boots the next time.\n"
        printf "d. Remember to enter the same password as the MOK.\n"
        printf "Driver installation will fail without the above steps.\n"
        printf "In case you miss any of these steps, you can also manually repeat the process later with the command “sudo update-secureboot-policy --enroll-key” and reboot.\n"
        printf "Ensure steps a, b, c and d.\n"
        printf "Resuming installation in a minute...${NORMAL_C}\n"
        sleep 60
    fi
}

## Let the DMS systemd service see the path variable in mining operating systems(based on Ubuntu 18.04) to enable cross vendor GPU support
add-mining-os-path() {

    # Full path to the nunet-dms systemd service file
    nunet_dms_systemd_file="/etc/systemd/system/nunet-dms.service"

    # Get the current PATH
    mining_os_path=$(echo $PATH)

    # Check if the PATH already exists in the file(avoid adding multiple entries if GPU onboarding is required more than once)
    if ! grep -q "Environment=\"PATH=${mining_os_path}\"" ${nunet_dms_systemd_file}; then

        # Use sed to append the new Environment line after the existing one
        sudo sed -i "/Environment=/a Environment=\"PATH=${mining_os_path}\"" ${nunet_dms_systemd_file}

        # Reload the systemd daemon
        sudo systemctl daemon-reload

        # Restart the service
        sudo systemctl restart nunet-dms
    fi
}



## Install NVIDIA GPU Drivers and Container Runtime
onboard-gpu() {

    # WSL code block

    # Use the uname command with the -a option to get system information
    system_info=$(uname -a)

    # Use grep to search for the string "microsoft" in the system information
    if echo "$system_info" | grep -qi "microsoft"; then
    # The string "microsoft" was found, so this is a WSL console
        printf "${INFO_C}You are using Windows Subsystem for Linux. Make sure you have installed the latest Windows Driver for your NVIDIA GPU before proceeding. AMD GPUs on WSL is not supported.${NORMAL_C}\n"
        sleep 5 # adding some time to read the message

        # Check if nvidia-smi is available on WSL
        if ! command -v /usr/lib/wsl/lib/nvidia-smi > /dev/null; then
          printf "${BAD_C}Error: nvidia-smi is not installed. Make sure you have installed the latest Windows Driver for your NVIDIA GPU and try again."
          exit
        fi

        # Run nvidia-smi -L and save all NVIDIA GPU names on the machine
        nvidia_gpu_names=$(nvidia-smi -L 2>/dev/null)
        if [[ $nvidia_smi_output =~ "No devices were found" ]]; then
           printf "${BAD_C}Error: No NVIDIA GPUs were detected.${NORMAL_C}"
           exit
        else
           printf "${GOOD_C}NVIDIA GPU(s) detected.${NORMAL_C}\n"
           # Print the GPU names
           printf "${INFO_C}Available GPU(s):\n$nvidia_gpu_names${NORMAL_C}\n"
           printf "${INFO_C}-----Starting NVIDIA Container Runtime Installation-----${NORMAL_C}\n"
           sleep 5 # add some time to see available GPUs on the machine
           curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | sudo apt-key add -
           distribution=$(
               . /etc/os-release
               echo $ID$VERSION_ID
           )
           curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list
           sudo apt update
           sudo apt -y install nvidia-container-runtime
           sudo systemctl restart docker
           printf "${INFO_C}Note: For best performance without sharing resources, a dedicated Linux machine is highly recommended for running ML jobs on NuNet.${NORMAL_C}\n"
           sleep 5
           printf "${GOOD_C}-----NVIDIA Container Runtime Installed-----${NORMAL_C}\n"
           exit
         fi
    fi

    #Linux code block

    # Get Linux OS information to look for mining operating systems
    OS_INFO=$(cat /etc/*-release)

    # Check for a mining OS
    if echo "$OS_INFO" | grep -Eiq "Hive|Rave|PiMP|Minerstat|SimpleMining|NH|Miner|SM|MMP"; then
        mining_os=true
    fi

    if [ "$mining_os" = true ]; then
        add-mining-os-path
    fi

    nvidia_gpu_exists="$(lshw -c display 2>/dev/null | grep -i nvidia)"
    amd_gpu_exists="$(lshw -c display 2>/dev/null | grep -i 'amd/ati')"

    # CHECK IF THERE IS NVIDIA GPU
    if [ -n "$nvidia_gpu_exists" ]; then
        printf "${GOOD_C}GPU device found! ${NORMAL_C}\n"
        all_gpus=$(nvidia-smi -L 2>/dev/null)
        if [ $? -eq 0 ]; then
            printf "${INFO_C}All available NVIDIA GPU(s):\n$all_gpus ${NORMAL_C}\n"
            sleep 3 #adding some time for the onboarder to see all GPUs on the machine

            gpu_driver_version="$(nvidia-smi 2>/dev/null | grep Driver | awk '{print "NVIDIA " $4 " " $5 " " $6}')" # the gpu driver version
            gpu_driver_var="$(nvidia-smi 2>/dev/null | grep Driver | awk '{print $4}')" # a variable with value "Driver"
            
            # First check whether the Linux OS is a mining distro with preinstalled GPU drivers
            # if machine is running a mining OS, we skip NVIDIA GPU driver installation and only install NVIDIA container runtime
            if [ "$mining_os" = true ]; then
                printf "${INFO_C}Mining operating system detected. Skipping installation of NVIDIA GPU Driver.${NORMAL_C}\n"
            # if gpu_driver_var is not empty we skip GPU driver installation AND only install NVIDIA container runtime
            elif [ -n "$gpu_driver_var" ]; then #IF $gpu_driver_var contains the word "Driver"
                printf "${INFO_C}$gpu_driver_version is already installed. Skipping installation of NVIDIA GPU Driver.${NORMAL_C}\n"
            else
                install_nvidiagpu_driver
            fi
        else
            install_nvidiagpu_driver
        fi
        printf "${INFO_C}-----Starting NVIDIA Container Runtime Installation-----${NORMAL_C}\n"
        curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | sudo apt-key add -
        distribution=$(
            . /etc/os-release
            echo $ID$VERSION_ID
        )
        curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list
        sudo apt update
        sudo apt install -y nvidia-container-runtime
        sudo systemctl restart docker
        printf "${GOOD_C}-----NVIDIA Container Runtime Installed-----${NORMAL_C}\n"
    fi

    # CHECK IF THERE IS AMD GPU
    if [ -n "$amd_gpu_exists" ]; then
        printf "${GOOD_C}GPU device found! ${NORMAL_C}\n"
        all_gpus=$(rocm-smi --showid --showproductname 2>/dev/null | grep 'Card series' | awk -F'[][]' '{printf "AMD " $4 "\n"}')
        if [ $? -eq 0 ]; then
            printf "${INFO_C}All available AMD GPU(s):\n$all_gpus ${NORMAL_C}\n"
            sleep 3 #adding some time for the onboarder to see all GPUs on the machine

            gpu_driver_version="$(rocm-smi --showdriverversion 2>/dev/null | grep 'Driver version' | awk '{print $3}')"

            # First check whether the Linux OS is a mining distro with preinstalled GPU drivers
            # if machine is running a mining operating system, we skip AMD GPU driver installation and no container runtime installation is necessary
            if [ "$mining_os" = true ]; then
                printf "${INFO_C}Mining operating system detected. Skipping installation of AMD GPU ROCm Kernel Driver.${NORMAL_C}\n"
            # if gpu_driver_var is not empty we skip GPU driver installation and no container runtime installation is necessary
            elif [ -n "$gpu_driver_version" ]; then #IF $gpu_driver_version is not empty
                printf "${INFO_C}AMD ROCm Kernel Driver Version: $gpu_driver_version is already installed. Skipping installation of AMD GPU ROCm Kernel Driver.${NORMAL_C}\n"
            else
                install_amdgpu_driver
            fi
        else
            install_amdgpu_driver
        fi    
    else
        # IF THERE IS NO NVIDIA or AMD GPU THE nvidia_gpu_exists AND amd_gpu_exists VARIABLE WILL BE EMPTY SO WE REPORT MISSING GPU
        printf "${INFO_C}This machine does not have an NVIDIA or AMD GPU. Skipping GPU Driver Installation.${NORMAL_C}\n"
    fi
}

install_nvidiagpu_driver()
{
    linux_distro=$(grep -Po "(?<=^ID=).+" /etc/os-release | sed 's/"//g') # we add support for specific linux distributions through this variable.

    secure_boot_check
    printf "${INFO_C}-----Starting NVIDIA GPU Driver Installation-----${NORMAL_C}\n"
    if [[ $linux_distro = "ubuntu" ]]; then
        sudo apt update
        # Detect the Ubuntu version
        ubuntu_version=$(lsb_release -sr)
        # Install the correct NVIDIA driver based on the Ubuntu version
        if [ "$ubuntu_version" == "18.04" ]; then
            sleep 1 # without this, text from the "apt update" output may get overlapped with the below line when printing
            printf "${INFO_C}Detected Ubuntu 18.04. Installing NVIDIA Driver Series 520...${NORMAL_C}"
            sudo apt install nvidia-driver-525 # may change later based on ML performance
        elif [ "$ubuntu_version" == "20.04" ]; then
            sleep 1 # without this, text from the "apt update" output may get overlapped with the below line when printing
            printf "${INFO_C}Detected Ubuntu 20.04. Installing NVIDIA Driver Series 520...${NORMAL_C}"
            sudo apt install nvidia-driver-525 # may change later based on ML performance
        elif [ "$ubuntu_version" == "22.04" ]; then
            sleep 1 # without this, text from the "apt update" output may get overlapped with the below line when printing
            printf "${INFO_C}Detected Ubuntu 22.04. Installing NVIDIA Driver Series 520...${NORMAL_C}"
            sudo apt install nvidia-driver-525 # may change later based on ML performance
        else
            printf "${BAD_C}Unsupported Ubuntu version: $ubuntu_version${NORMAL_C}"
        fi
        gpu_driver_version="$(nvidia-smi 2>/dev/null | grep Driver | awk '{print "NVIDIA " $4 " " $5 " " $6}')" # the gpu driver version
        gpu_driver_var="$(nvidia-smi 2>/dev/null | grep Driver | awk '{print $4}')" # a variable with value "Driver"

        if [[ $gpu_driver_var = "Driver" ]]; then
            printf "${GOOD_C}-----NVIDIA GPU Driver $gpu_driver_version Installed-----${NORMAL_C}\n"
        else
            printf "${BAD_C}-----NVIDIA GPU Driver Still Not Found. Please Reboot and Retry-----${NORMAL_C}\n"
        fi

    elif [[ $linux_distro = "kali" ]]; then
        sudo apt update && sudo apt install -y nvidia-driver
        gpu_driver_var="$(nvidia-smi 2>/dev/null | grep Driver | awk '{print $4}')"
        gpu_driver_version="$(nvidia-smi 2>/dev/null | grep Driver | awk '{print "NVIDIA " $4 " " $5 " " $6}')"

        if [[ $gpu_driver_var = "Driver" ]]; then
            printf "${GOOD_C}-----NVIDIA GPU Driver $gpu_driver_version Installed-----${NORMAL_C}\n"
        else
            printf "${BAD_C}-----NVIDIA GPU Driver Still Not Found. Please Reboot and Retry-----${NORMAL_C}\n"
        fi
    else
        printf "${INFO_C}Currently, only Ubuntu and Kali Linux Distributions are supported. But we will definitely add support for more distros in future.${NORMAL_C}\n"
    fi
}

install_amdgpu_driver()
{
    linux_distro=$(grep -Po "(?<=^ID=).+" /etc/os-release | sed 's/"//g') # we add support for specific linux distributions through this variable.

    secure_boot_check
    printf "${INFO_C}-----Starting AMD GPU Driver Installation-----${NORMAL_C}\n"
    if [[ $linux_distro = "ubuntu" ]]; then
        sudo apt update
        # Detect the Ubuntu version
        ubuntu_version=$(lsb_release -sr)
        # Install the correct AMD GPU driver based on the Ubuntu version

        if [ "$ubuntu_version" == "20.04" ]; then
            sleep 1 # without this, text from the "apt update" output may get overlapped with the below line when printing
            printf "${INFO_C}Detected Ubuntu 20.04. Installing AMDGPU ROCm Driver 5.5...${NORMAL_C}"
            wget https://repo.radeon.com/amdgpu-install/5.5/ubuntu/focal/amdgpu-install_5.5.50500-1_all.deb 
            sudo apt install ./amdgpu-install_5.5.50500-1_all.deb
            sudo amdgpu-install --usecase=rocm            
            rm -rf amdgpu-install_5.5.50500-1_all.deb
            sudo usermod -a -G video $LOGNAME
            sudo usermod -a -G render $LOGNAME
        elif [ "$ubuntu_version" == "22.04" ]; then
            sleep 1 # without this, text from the "apt update" output may get overlapped with the below line when printing
            printf "${INFO_C}Detected Ubuntu 22.04. Installing AMDGPU ROCm Driver 5.5...${NORMAL_C}"
            wget https://repo.radeon.com/amdgpu-install/5.5/ubuntu/jammy/amdgpu-install_5.5.50500-1_all.deb 
            sudo apt install ./amdgpu-install_5.5.50500-1_all.deb
            sudo amdgpu-install --usecase=rocm            
            rm -rf amdgpu-install_5.5.50500-1_all.deb
            sudo usermod -a -G video $LOGNAME
            sudo usermod -a -G render $LOGNAME
        else
            printf "${BAD_C}Unsupported Ubuntu version: $ubuntu_version${NORMAL_C}"
        fi

        gpu_driver_version="$(rocm-smi --showdriverversion 2>/dev/null | grep 'Driver version' | awk '{print $3}')"

        if [[ -n $gpu_driver_version ]]; then
            printf "${GOOD_C}-----AMDGPU driver version: $gpu_driver_version Installed-----${NORMAL_C}\n"
        else
            printf "${BAD_C}-----AMDGPU Driver Not Found. Please Reboot and Retry-----${NORMAL_C}\n"
        fi

    else
        printf "${INFO_C}Currently, only Ubuntu Distributions are supported. But we will definitely try to add support for more distros in future.${NORMAL_C}\n"
    fi
}



# Onboarding for ML jobs
onboard-ml()
{
    # Check if both NVIDIA and AMD GPUs are detected
    if [[ $(lshw -c display 2>/dev/null | grep -i nvidia) && $(lshw -c display 2>/dev/null | grep -i 'amd/ati') ]]; then
        printf "${GOOD_C}Both NVIDIA and AMD GPUs detected.${NORMAL_C}\n"
        printf "${INFO_C}Pulling CUDA and ROCm based PyTorch and TensorFlow images.${NORMAL_C}\n"
        sudo docker pull registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/tensorflow
        sudo docker pull registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch
        sudo docker pull registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/tensorflow-amd
        sudo docker pull registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch-amd
        ml_info
    
    # Check if NVIDIA GPUs are detected
    elif [[ $(lshw -c display 2>/dev/null | grep -i nvidia) ]]; then
        printf "${GOOD_C}NVIDIA GPUs detected.${NORMAL_C}\n"
        printf "${INFO_C}Pulling CUDA based PyTorch and TensorFlow images.${NORMAL_C}\n"
        sudo docker pull registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/tensorflow
        sudo docker pull registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch
        ml_info
    
    # Check if AMD GPUs are detected
    elif [[ $(lshw -c display 2>/dev/null | grep -i 'amd/ati') ]]; then
        printf "${GOOD_C}AMD GPUs detected.${NORMAL_C}\n"
        printf "${INFO_C}Pulling ROCm based PyTorch and TensorFlow images.${NORMAL_C}\n"
        sudo docker pull registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/tensorflow-amd
        sudo docker pull registry.gitlab.com/nunet/ml-on-gpu/ml-on-gpu-service/develop/pytorch-amd
        ml_info

    # If no GPUs are detected
    else
        printf "${BAD_C}No NVIDIA or AMD GPUs detected.${NORMAL_C}\n"
        printf "${INFO_C}Ensure your machine has compatible GPU(s) and has been onboarded with the 'nunet onboard-gpu' command.${NORMAL_C}\n"
    fi
}

## shell websocket connection  

shell(){
    # echo "to install on ubuntu run the following:"
    # echo "sudo wget -qO /usr/local/bin/websocat https://github.com/vi/websocat/releases/latest/download/websocat.x86_64-unknown-linux-musl"
    if [[ "$1" = "--node-id" &&  $# -eq 2 ]]; then
        websocat ws://$DMS_HOST:$DMS_PORT/api/v1/peers/ws?nodeID=$2
    else
        echo "Please enter a --node-id <the-node-id>"
    fi
}

log(){
    echo -e "Collecting logs.. \n"
    mkdir -m 777 -p /tmp/nunet-log/dms-log
    nunet_log_dir='/tmp/nunet-log'
    # collect DMS log and save it to files based on boot number
    num_of_boot=$(journalctl -u nunet-dms  --list-boots -r | wc -l)
    for (( num=1; num<$num_of_boot; num++))
    do
        if [[ "$(journalctl -u nunet-dms -b $num | sed -n 2p)" != '-- No entries --' ]]; then
            journalctl -u nunet-dms -b $num > $nunet_log_dir/dms-log/dms_log.$num
        fi
    done

    #archive all the logs and retorn path
    tar -cf $nunet_log_dir/nunet-log.tar --exclude=$nunet_log_dir/nunet-log.tar -P $nunet_log_dir
    if [ $? -eq 0 ]; then
           rm -r $nunet_log_dir/dms-log
    fi

    echo -e "$nunet_log_dir/nunet-log.tar \n"

}

version(){
    N_DMS_VERSION=$(curl -s $DMS_HOST:$DMS_PORT/swagger/doc.json | jq -r .info.version)
    echo "DMS Version: $N_DMS_VERSION"
}

check_dms_run() {
    N_CHECK_DMS=$(ss -tnlp 2>/dev/null | grep ":$DMS_PORT")
    if [[ ! $? -eq 0 ]] ; then
        printf "${BAD_C}Looks like NuNet DMS is not running."
        printf "Please check with ${INFO_C}'systemctl status nunet-dms.service'${NORMAL_C}\n"
        exit
    fi
}


cmds=("capacity" "wallet" "onboard" "info" "peer" "onboard-gpu" "onboard-ml" "shell" "chat" "log" "resource-config" "version" "default-depreq-peer")

if [ $# -eq  0 ] ; then
    usage
else
    in_args=($@)
    arg=$1
    argargs=("${in_args[@]:1}")
    cmd_valid=0
    for cmd in "${cmds[@]}"; do
        if [[ $arg == $cmd ]]; then
            cmd_valid=1
            break
        fi
    done

    if [[ $cmd_valid -eq 0 ]] ; then
        printf "${BAD_C}Error: Command \"$arg\" not found.${NORMAL_C}\n"
        usage
    else
        check_dms_run
        $cmd ${argargs[@]}
    fi

fi
